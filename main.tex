\documentclass[12pt]{article}

\input{Preamble.tex}

\newcommand{\lb}{\left(}
\newcommand{\rb}{\right)}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

%\makeatletter
%\def\BState{\State\hskip-\ALG@thistlm}
%\makeatother

\begin{document}

\section{Начальные распределения для задачи двух тел}

\subsection{MCMC-sampling}

Предположим мы генерируем последовательность случайных величин, $\left\{ X_0, X_1, X_2, \dots \right\}$, такую что в каждый момент $t \geq 0$ следующее состояние $X_{t + 1}$ выбирается исходя из распределения $P \lb X_{t+1} | X_t \rb$, которое зависит от текущего состояния $X_t$, но не от предыдущего набора состояний $\left\{ X_0, X_1, X_2 ... X_{t - 1} \right\}$. То есть, состояние $X_{t + 1}$ определяется исключительно предыдущим $X_t$. Такая последовательность состояний называется \textit{цепью Маркова}. \par
Рассмотрим алгоритм Метрополиса-Гастингса, позволяющий получать последовательность точек -- элементов Марковской цепи -- распределенную согласно заданной плотности вероятности $\pi(\cdot)$.
\begin{algorithm}
\begin{algorithmic}[1]
		\caption{Metropolis-Hastings algorithm [1]}\label{metropolis}
\State Initialize $x^{(0)} \sim q(x)$
\State \textbf{for} iteration $i = 1, 2, \dots$ \textbf{do}
\State \quad Propose: $x^{cand} \sim q \lb x^{(i)} | x^{(i-1)} \rb$
\State \quad Acceptance probability:
\State \qquad $\alpha \lb x^{cand} | x^{(i-1)} \rb = \min \left\{ 1, \frac{q \lb x^{(i-1)} | x^{cand} \rb \pi \lb x^{(cand)} \rb }{ q \lb x^{cand} | x^{(i-1)} \rb \pi \lb x^{(i-1)} \rb} \right\}$
\State \quad $u \sim$ Uniform(u; 0, 1)
\State \quad \textbf{if} $u < \alpha$ \textbf{then}
\State \qquad Accept the proposal: $x^{(i)} \gets x^{cand}$
\State \quad \textbf{else}
\State \qquad Reject the proposal: $X^{(i)} \gets x^{(i-1)}$
\State \quad \textbf{end if}
\State \textbf{end for}
\end{algorithmic}
\end{algorithm}

Первым шагом алгоритма является выбор случайной точки (эта величина выбирается определенным образом на основе распределения; я же выбирал ее совершенно случайным образом, но так, чтобы она не оказалась в какой-то физически маловероятной области). Следующий за ним главный цикл алгоритма состоит из трех частей: (1) Получать следующую точку ("кандидата") $x^{cand}$ исходя из вспомогательного распределения $q \lb x^{(i)} | x^{(i-1)} \rb$; (2) Рассчитать вероятность перехода в новую точку $\alpha \lb x^{cand} | x^{(i-1)} \rb$, основываясь на распределении $q$ и функции распределения $\pi$; (3) Принять новую точку с вероятностью $\alpha$. \par
Обратим внимание на то, что точка, полученная исходя из вспомогательного распределения $q(\cdot)$, принимается не всегда, а лишь с вероятностью $\alpha \lb \cdot \rb$. Рассматривают вспомогательные распределения двух классов -- симметричные и асимметричные. Симметричным называется распределение, удовлетворяющее следующему соотношению
\begin{gather}
		q \lb x^{(i)} | x^{(i-1)} \rb = q \lb x^{(i-1)} | x^{(i)} \rb \notag
\end{gather}
К часто используемым симметричным распределениям относятся гауссово и равномерное распределения. В качестве примера рассмотрим вспомогательное распределение Гауссса: 
\begin{gather}
		x^{cand} = x^{(i-1)} + Normal(0, \sigma) \notag
\end{gather}

Понятно, что $Normal( x^{cand} - x^{(i-1)}; 0, \sigma ) = Normal( x^{(i-1)} - x^{cand}; 0, \sigma)$, то есть Гауссово распределение в действительности задает симметричное вспомогательное распределение. Среднеквадратичное отклонение $\sigma$ является параметром модели. Значение этого параметра будет определять динамику Марковской цепи в рассматриваемом пространстве. \par
В случае симметричных вспомогательных распределений выражение для вероятности выбора новой точки $\alpha(\cdot)$ существенно упрощается:
\begin{gather}
		\alpha \lb x^{cand} | x^{(i-1)} \rb = \min \left\{ 1, \frac{\pi \lb x^{cand} \rb}{\pi \lb x^{(i - 1)} \rb} \right\} \notag 
\end{gather}

Заметим, что если плотность вероятности ( точнее говоря, величина, пропорциональная плотности вероятности ) в новой точке $\pi \lb x^{cand} \rb$ больше, чем плотность вероятности в текущей $\pi \lb x^{\lb i - 1 \rb} \rb$, то их отношение будет больше $1$, а значит вероятность перехода в новую точку будет равна 1: $\alpha \lb x^{cand} | x^{(i - 1)} \rb = 1$. Другими словами, если новая точка выбрана таким образом, что плотность вероятности в ней больше, чем в текущей, то в нее осуществляется переход. Устройство алгоритма таково, что Марковская цепь "склонна" посещать те точки пространства, в которых моделируемая плотность вероятности выше. Однако, если новая точка была выбрана таким образом, что плотность вероятности в ней меньше, чем в текущей, то тогда вероятность перейти в нее будет определяться отношением плотностей вероятности:
\begin{gather}
		\alpha \lb x^{cand} | x^{(i - 1)} \rb = \frac{\pi \lb x^{cand} \rb}{\pi \lb x^{(i - 1)} \rb} \notag
\end{gather}

То есть, если вероятность в новой точке будет мала по сравнению с текущей, то и переход в нее будет маловероятен. \par
Вид вероятности перехода в новую точку из текущей определяется \textit{условием детального баланса} [2]. Последнее гарантирует, что полученная Марковская цепь в действительности будет удовлетворять заданной плотности вероятности.

\newpage
\section{Литература}
\begin{enumerate}
	\item Yildirim I. Bayesian Inference: Metropolis-Hastings Sampling. MIT Online Library
	\item Gilks, W.R., Richardson, S., \& Spiegelhalter, D.J. (1996). \textit{Markov Chain Monte Carlo in Practice}. London: Chapman and Hall.
\end{enumerate}

\end{document}
